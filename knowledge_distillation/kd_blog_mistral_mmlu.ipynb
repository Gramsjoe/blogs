{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%conda install conda=24.1.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51a6cc997872b1f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52605bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d435b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    MistralForCausalLM,\n",
    ")\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import boto3\n",
    "import tarfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_path = \"/home/ec2-user/SageMaker/transformers_cache/\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(model_path)\n",
    "except OSError:\n",
    "    print(\"Creation of the directory %s failed or it already exists\" % model_path)\n",
    "else:\n",
    "    print(\"Successfully created the directory %s\" % model_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f04886f2be62361"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12754267",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "teacher_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
    "dataset_id = \"cais/mmlu\"\n",
    "dataset_config = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e80179",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"Here's our sanity check.\"\n",
    "\n",
    "assert teacher_tokenizer(sample) == student_tokenizer(sample), (\n",
    "    \"Tokenizers need to have the same output! \"\n",
    "    f\"{teacher_tokenizer(sample)} != {student_tokenizer(sample)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f50ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "del teacher_tokenizer\n",
    "del student_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0be7f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_mapping = {\n",
    "    1: \"A\",\n",
    "    2: \"B\",\n",
    "    3: \"C\",\n",
    "    4: \"D\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87411e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_dataset_to_dict(dataset):\n",
    "    return {key: dataset[key] for key in dataset.column_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be711d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_few_shot():\n",
    "    random_key = random.choice(list(few_shot_dict.keys()))\n",
    "    random_value = few_shot_dict[random_key]\n",
    "\n",
    "    return random_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ab3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_question_to_prompt(data, show_answer=False):\n",
    "    prompt = ''\n",
    "    prompt += f\"{data['question']}\\n\\n\"\n",
    "\n",
    "    for idx, choice in enumerate(data['choices'], start=1):\n",
    "        prompt += f\"{idx_mapping[idx]}. {choice}\\n\"\n",
    "    \n",
    "    if show_answer:\n",
    "        prompt += f\"\\nAnswer: {data['answer']}\\n\\n\"\n",
    "    else:\n",
    "        prompt += f\"\\nAnswer:\"\n",
    "        \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a4364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_few_shot(subject_filter):\n",
    "    index_list = [i for i, subject in enumerate(dev_dataset['subject']) if subject == subject_filter]\n",
    "\n",
    "    new_data = [\n",
    "        {\n",
    "            'question': dev_dataset['question'][i],\n",
    "            'subject': dev_dataset['subject'][i],\n",
    "            'choices': dev_dataset['choices'][i],\n",
    "            'answer': dev_dataset['answer'][i]\n",
    "        }\n",
    "        for i in index_list\n",
    "    ]\n",
    "    \n",
    "    few_shot_prompt = ''\n",
    "    \n",
    "    for data in new_data:\n",
    "        few_shot_prompt += append_question_to_prompt(data, show_answer=True)\n",
    "        \n",
    "\n",
    "    return few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfd78ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_subject(subject):\n",
    "    l = subject.split(\"_\")\n",
    "    s = \"\"\n",
    "    for entry in l:\n",
    "        s += \" \" + entry\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "424f13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process(data):\n",
    "    subject = data['subject']\n",
    "\n",
    "    prompt = f\"The following are multiple choice questions (with answers) about {format_subject(subject)}.\\n\\n\"\n",
    "    prompt += few_shot_dict[subject]\n",
    "    prompt += append_question_to_prompt(data)\n",
    "    \n",
    "    tokenized_prompt = tokenizer(prompt, truncation=True, max_length=4096, padding=True)\n",
    "\n",
    "    return tokenized_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ca1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(data):\n",
    "    prompt = f\"The following are multiple choice questions (with answers) about a random subject.\\n\\n\"\n",
    "    prompt += random_few_shot()\n",
    "    prompt += append_question_to_prompt(data)\n",
    "    \n",
    "    tokenized_prompt = tokenizer(prompt, truncation=True, max_length=4096, padding=True)\n",
    "\n",
    "    return tokenized_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dacd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_id, dataset_config)\n",
    "\n",
    "train_dataset = dataset['auxiliary_train']\n",
    "test_dataset = dataset['test']\n",
    "dev_dataset = dataset['dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d220fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_dict = {}\n",
    "dev_dict = hf_dataset_to_dict(dev_dataset)\n",
    "subjects = list(set(dev_dict['subject']))\n",
    "for subject in subjects:\n",
    "    few_shot_dict[subject] = get_subject_few_shot(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "add900d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(train_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.map(test_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43617ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = MistralForCausalLM.from_pretrained(teacher_id, cache_dir=model_path)\n",
    "print(teacher_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372783d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = MistralForCausalLM.from_pretrained(student_id, cache_dir=model_path)\n",
    "print(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    return {\n",
    "        \"accuracy\": acc[\"accuracy\"],\n",
    "    }"
   ],
   "metadata": {},
   "id": "b7d073b0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762adb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542ce5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a04ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset[:1]['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset[:1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fdeeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset[200:201]['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd972b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset[200:201]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971fb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[1000:1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc04edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(few_shot_dict['professional_accounting'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
