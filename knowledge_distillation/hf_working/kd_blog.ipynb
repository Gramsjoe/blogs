{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca61851",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import boto3\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffa3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b729868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./models/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521864eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = \"gpt2\"\n",
    "teacher_id = \"gpt2-medium\"\n",
    "dataset_id = \"glue\"\n",
    "dataset_config = \"sst2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a621a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentence\"], truncation=True, max_length=256, padding=True\n",
    "    )\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b027d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    return {\n",
    "        \"accuracy\": acc[\"accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c15181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        # place teacher on same device as student\n",
    "        self._move_model_to_device(self.teacher, self.model.device)\n",
    "        self.teacher.eval()\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # compute student output\n",
    "#         print(\"NEW!!!!! compute student output\")\n",
    "#         for key, value in inputs.items():\n",
    "#             if key != \"outputs teacher\":\n",
    "#                 print(f\"{key}: {value}\")\n",
    "\n",
    "        outputs_student = model(**inputs)\n",
    "#         print(\"outputs student:\", outputs_student)\n",
    "        student_loss = outputs_student.loss\n",
    "#         print(\"student loss:\", student_loss)\n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher(**inputs)\n",
    "#             print(\"outputs teacher:\", outputs_teacher)\n",
    "        # assert size\n",
    "        assert (\n",
    "            outputs_student.logits.size() == outputs_teacher.logits.size()\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Soften probabilities and compute distillation loss\n",
    "        loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        loss_logits = loss_function(\n",
    "            F.log_softmax(\n",
    "                outputs_student.logits / self.args.temperature, dim=-1\n",
    "            ),\n",
    "            F.softmax(\n",
    "                outputs_teacher.logits / self.args.temperature, dim=-1\n",
    "            ),\n",
    "        ) * (self.args.temperature**2)\n",
    "        # Return weighted student loss\n",
    "        loss = (\n",
    "            self.args.alpha * student_loss\n",
    "            + (1.0 - self.args.alpha) * loss_logits\n",
    "        )\n",
    "        return (loss, outputs_student) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb33ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"Here's our sanity check.\"\n",
    "\n",
    "assert teacher_tokenizer(sample) == student_tokenizer(sample), (\n",
    "    \"Tokenizers need to have the same output! \"\n",
    "    f\"{teacher_tokenizer(sample)} != {student_tokenizer(sample)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del teacher_tokenizer\n",
    "del student_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa629d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(teacher_id)\n",
    "# tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf76276",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_id, dataset_config)\n",
    "\n",
    "tokenized_dataset = dataset.map(process, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "print(tokenized_dataset[\"test\"].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eab6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tokenized_dataset[\"train\"].features[\"labels\"].names\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training args\n",
    "training_args = DistillationTrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=1,\n",
    "    auto_find_batch_size=True,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "    fp16=True,\n",
    "    learning_rate=6e-5,\n",
    "    seed=8855,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    alpha=0.5,\n",
    "    temperature=4.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher_id,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    student_id,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dbf842",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6313cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "student_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad216438",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52434a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DistillationTrainer(\n",
    "    student_model,\n",
    "    training_args,\n",
    "    teacher_model=teacher_model,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa39e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = AutoModelForSequenceClassification.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdedc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3941293",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Hello, my dog is cute\"\n",
    "max_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer([input_text], truncation=True, padding='max_length', max_length=max_length, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ea78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.to(tokens['input_ids'].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tokens['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d577502",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trace = torch.jit.trace(final_model, tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trace.save('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feef331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path = 'results'\n",
    "tar_gz_file = \"model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(tar_gz_path, \"w:gz\") as tar:\n",
    "    tar.add(model_dir, arcname=os.path.basename(model_dir))\n",
    "\n",
    "print(f\"Compressed and archived {model_dir} to {tar_gz_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(\".\", tar_gz_file)\n",
    "s3_file = f\"{sess.default_bucket()}/{s3_model_path}/{tar_gz_file}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5896b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s3.upload_file(model_file, sess.default_bucket(), f\"{s3_model_path}/{tar_gz_file}\")\n",
    "    print(f'Uploaded {model_file} to {s3_file}')\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while uploading file {model_file}, {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
